{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72223fb3",
   "metadata": {},
   "source": [
    "This is a script to verify that commonly used metrics for binary classification are not invariant to arbitrary class distributions. Suppose we are given a binary classifier which predicts class 0 perfectly (100% accuracy) and class 1 with 50% accuracy. Now consider two test sets: the first contains 1 sample of class 0 and 2 samples of class 1, the second includes 2 samples for both classes. Assuming the samples are i.i.d, the predicted labels/scores are given in the following cell. \n",
    "\n",
    "We evaluate 6 metrics: weighted F1, matthews_corrcoef ($\\phi$), cohen_kappa_score ($\\kappa$), average_precision_score (AUPRC) and our proposed balanced acc and balance F1, the result follows:\n",
    "\n",
    "\n",
    "| Metric | Dataset 1 | Dataset 2 | Invariant |\n",
    "| :----: | :-------: | :-------: | :-------: |\n",
    "| Weighted F1 | 0.6667 | 0.7333 | ❌ |\n",
    "| $\\phi$ | 0.5000 | 0.5774 | ❌  |\n",
    "| $\\kappa$ | 0.4000 | 0.5000 | ❌  |\n",
    "| AUPRC | 0.8333 | 0.7500 | ❌  |\n",
    "| Balanced Acc | 0.7500 | 0.7500 | ✅ |\n",
    "| Balanced F1 | 0.7333 | 0.7333 | ✅ |\n",
    "\n",
    "\n",
    "**Conclusion: only the proposed balanced metrics are invariant to different class distributions in datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7057fde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 for dataset 1: 0.6667\n",
      "Weighted F1 for dataset 2: 0.7333\n",
      "phi coefficient for dataset 1: 0.5000\n",
      "phi coefficient for dataset 2: 0.5774\n",
      "cohen kappa for dataset 1: 0.4000\n",
      "cohen kappa for dataset 2: 0.5000\n",
      "AUPRC for dataset 1: 0.8333\n",
      "AUPRC for dataset 2: 0.7500\n",
      "Balanced Acc for dataset 1: 0.7500\n",
      "Balanced Acc for dataset 2: 0.7500\n",
      "Balanced F1 for dataset 1: 0.7333\n",
      "Balanced F1 for dataset 2: 0.7333\n"
     ]
    }
   ],
   "source": [
    "import script._init_paths\n",
    "from sklearn.metrics import matthews_corrcoef, cohen_kappa_score, average_precision_score, f1_score\n",
    "from lib.core.evaluate import balanced_f1, balanced_accuracy_score\n",
    "\n",
    "\n",
    "# Dataset 1\n",
    "gt1 = [0, 1, 1] # ground truth labels\n",
    "pred1 = [0, 0, 1] # predicted labels/scores\n",
    "\n",
    "# Dataset 2\n",
    "gt2 = [0, 0, 1, 1] # ground truth labels\n",
    "pred2 = [0, 0, 0, 1] # predicted labels/scores\n",
    "\n",
    "print('Weighted F1 for dataset 1: %.4f' %(f1_score(gt1, pred1, average=\"weighted\")))\n",
    "print('Weighted F1 for dataset 2: %.4f' %(f1_score(gt2, pred2, average=\"weighted\")))\n",
    "print('phi coefficient for dataset 1: %.4f' %(matthews_corrcoef(gt1, pred1)))\n",
    "print('phi coefficient for dataset 2: %.4f' %(matthews_corrcoef(gt2, pred2)))\n",
    "print('cohen kappa for dataset 1: %.4f' %(cohen_kappa_score(gt1, pred1)))\n",
    "print('cohen kappa for dataset 2: %.4f' %(cohen_kappa_score(gt2, pred2)))\n",
    "print('AUPRC for dataset 1: %.4f' %(average_precision_score(gt1, pred1)))\n",
    "print('AUPRC for dataset 2: %.4f' %(average_precision_score(gt2, pred2)))\n",
    "print('Balanced Acc for dataset 1: %.4f' %(balanced_accuracy_score(gt1, pred1)))\n",
    "print('Balanced Acc for dataset 2: %.4f' %(balanced_accuracy_score(gt2, pred2)))\n",
    "print('Balanced F1 for dataset 1: %.4f' %(balanced_f1(gt1, pred1)))\n",
    "print('Balanced F1 for dataset 2: %.4f' %(balanced_f1(gt2, pred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae554047",
   "metadata": {},
   "source": [
    "As proven in Thm 1 of the paper, only the proposed balanced metrics are *invariant* to label distribution shift. Therefore, to retain consistency with the standard split (balanced test set), only these 2 metrics can be used on an *imbalanced* test set. As discussed in the paper, this enables a much larger test set for better quality and reliability of the evaluation statistics. We provide empirical evidence of this claim by running the following toy example.\n",
    "\n",
    "In the following cell, we consider a 3-way classification problem where there are only 10 samples for the tail class 2. We can construct an imbalanced test set with sample size [1000, 100, 10] for each class (used for the balanced metrics), while the maximum size of a balanced test set is [10, 10, 10] for each class (used for the rest non-invariant metrics). Suppose we are given a classifier that outputs logits/scores for each class following the probability table below:\n",
    "\n",
    "| Class | Dim 0 | Dim 1 | Dim 2 |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| 0     | Uniform(0, 3) | Uniform(0, 2) | Uniform(0, 1) | \n",
    "| 1     | Uniform(0, 2) | Uniform(0, 3) | Uniform(0, 2) | \n",
    "| 2     | Uniform(0, 1) | Uniform(0, 2) | Uniform(0, 3) | \n",
    "\n",
    "where Uniform(a, b) stands for an continuous uniform distribution on interval [a, b]. Given a random seed, we resample the model output from the probability table above and compute the balanced metrics and other metrics. We repeat the process for multiple random seeds and keep track of the standard devision of the metrics across all seeds:\n",
    "\n",
    "| Metric | # Seed=3 | # Seed=5 | # Seed=10 | # Seed=20 | # Seed=50 | # Seed=100 |\n",
    "| :----: | :----: | :----: | :----: | :----: | :----: | :----: | \n",
    "| Weighted F1 | 0.0322 | 0.0563 | 0.1036 |  0.0892 | 0.0760 | 0.0853 | \n",
    "| $\\phi$ | 0.0513 | 0.0800 |  0.1427 | 0.1281 | 0.1140 | 0.1275 | \n",
    "| $\\kappa$ | 0.0471 | 0.0800 |  0.1435 | 0.1281 | 0.1132 | 0.1269 | \n",
    "| AUPRC | 0.0369 | 0.0289 |  0.0625 | 0.0703 | 0.0696 | 0.0763 | \n",
    "| AUROC | 0.0295 | **0.0242** | 0.0539 | 0.0613 | 0.0602 | 0.0672 | \n",
    "| Balanced Acc | 0.0310 | 0.0414 |  0.0512 | 0.0471 | 0.0522 | 0.0483 | \n",
    "| Balanced F1 | **0.0286** | 0.0374 |  **0.0504** | **0.0463** | **0.0506** | **0.0468** | \n",
    "\n",
    "for each column, the metric with lowest standard deviation is **bolded**.\n",
    "\n",
    "**Conclusion: the proposed balanced metrics (especially balanced f1) achieve consistently lower variance thanks to their invariance to label distribution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "680251db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted f1 standard deviation: 0.0853\n",
      "Phi coefficient standard deviation: 0.1275\n",
      "Cohen kappa standard deviation: 0.1269\n",
      "AUPRC standard deviation: 0.0763\n",
      "AUROC standard deviation: 0.0672\n",
      "Balanced Acc standard deviation: 0.0483\n",
      "Balanced F1 standard deviation: 0.0468\n"
     ]
    }
   ],
   "source": [
    "import script._init_paths\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef, cohen_kappa_score, average_precision_score, f1_score, average_precision_score, roc_auc_score\n",
    "from lib.core.evaluate import balanced_f1, balanced_accuracy_score\n",
    "\n",
    "\n",
    "# Dataset random generator\n",
    "def data_gen(seed=0, samples=[10, 10, 10]):\n",
    "    np.random.seed(seed)\n",
    "    sample0, sample1, sample2 = samples[0], samples[1], samples[2]\n",
    "    gt0 = np.zeros(sample0)\n",
    "    score0 = np.concatenate([np.random.uniform(0, 3, sample0).reshape(-1, 1),\n",
    "                             np.random.uniform(0, 2, sample0).reshape(-1, 1),\n",
    "                             np.random.uniform(0, 1, sample0).reshape(-1, 1)], axis=1)\n",
    "\n",
    "    gt1 = np.ones(sample1)\n",
    "    score1 = np.concatenate([np.random.uniform(0, 2, sample1).reshape(-1, 1),\n",
    "                             np.random.uniform(0, 3, sample1).reshape(-1, 1),\n",
    "                             np.random.uniform(0, 2, sample1).reshape(-1, 1)], axis=1)\n",
    "\n",
    "    gt2 = np.ones(sample2) * 2\n",
    "    score2 = np.concatenate([np.random.uniform(0, 1, sample2).reshape(-1, 1),\n",
    "                             np.random.uniform(0, 2, sample2).reshape(-1, 1),\n",
    "                             np.random.uniform(0, 3, sample2).reshape(-1, 1)], axis=1)\n",
    "    \n",
    "    gt = np.concatenate([gt0, gt1, gt2])\n",
    "    score = np.concatenate([score0, score1, score2])\n",
    "    softmax = np.exp(score)/np.sum(np.exp(score), axis=1).reshape(-1, 1)\n",
    "    pred = np.argmax(score, axis=1)\n",
    "    return gt.astype('int16'), softmax, pred\n",
    "\n",
    "# Convert ground truth labels to one-hot labels\n",
    "def one_hot(gt):\n",
    "    one_hot = np.zeros((gt.size, gt.max() + 1))\n",
    "    one_hot[np.arange(gt.size), gt] = 1\n",
    "    return one_hot\n",
    "\n",
    "w_f1 = []\n",
    "phi = []\n",
    "ck = []\n",
    "auprc = []\n",
    "auroc = []\n",
    "b_acc = []\n",
    "b_f1 = []\n",
    "\n",
    "for seed in range(0, 100):\n",
    "    np.random.seed(seed)\n",
    "    gt, _, pred = data_gen(seed, samples=[1000, 100, 10])\n",
    "    b_acc.append(balanced_accuracy_score(gt, pred))\n",
    "    b_f1.append(balanced_f1(gt, pred))\n",
    "    gt, softmax, pred = data_gen(seed, samples=[10, 10, 10])\n",
    "    w_f1.append(f1_score(gt, pred, average=\"weighted\"))\n",
    "    phi.append(matthews_corrcoef(gt, pred))\n",
    "    ck.append(cohen_kappa_score(gt, pred))\n",
    "    auprc.append(average_precision_score(one_hot(gt), softmax))\n",
    "    auroc.append(roc_auc_score(one_hot(gt), softmax))\n",
    "\n",
    "print('Weighted f1 standard deviation: %.4f' %(np.std(w_f1)))\n",
    "print('Phi coefficient standard deviation: %.4f' %(np.std(phi)))\n",
    "print('Cohen kappa standard deviation: %.4f' %(np.std(ck)))\n",
    "print('AUPRC standard deviation: %.4f' %(np.std(auprc)))      \n",
    "print('AUROC standard deviation: %.4f' %(np.std(auroc)))\n",
    "print('Balanced Acc standard deviation: %.4f' %(np.std(b_acc)))\n",
    "print('Balanced F1 standard deviation: %.4f' %(np.std(b_f1)))\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f001b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImDrug",
   "language": "python",
   "name": "imdrug"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
